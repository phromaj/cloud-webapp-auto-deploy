### Project Structure
- /Users/lucas/Developer/cloud-webapp-auto-deploy
- ├── LICENSE
- ├── __pycache__
- │   ├── main.cpython-310.pyc
- │   ├── main.cpython-312.pyc
- │   ├── models.cpython-310.pyc
- │   └── models.cpython-312.pyc
- ├── aws.tf
- ├── codebase.md
- ├── inventory.ini
- ├── main-ssh.tf
- ├── main.tf
- └── swarm_init.yml
- 2 directories, 11 files


### /Users/lucas/Developer/cloud-webapp-auto-deploy/aws.tf
```
provider "aws" {  region = "eu-north-1"  # Changez la rgion selon vos besoins}resource "aws_security_group" "allow_all_tcp" {  name        = "allow_all_tcp"  description = "Allow all TCP inbound traffic"  ingress {    description = "Allow all TCP traffic"    from_port   = 0    to_port     = 65535  # Ouvrir tous les ports TCP    protocol    = "tcp"    cidr_blocks = ["0.0.0.0/0"]  # Autoriser depuis n'importe quelle adresse IP  }  egress {    from_port   = 0    to_port     = 0    protocol    = "-1"  # Autoriser tout le trafic sortant    cidr_blocks = ["0.0.0.0/0"]  }  tags = {    Name = "allow_all_tcp"  }}resource "aws_instance" "web" {  count         = 3  # Dployer 3 instances  ami           = "ami-01427dce5d2537266"  # AMI pour Debian  instance_type = "t3.micro"  # Petite instance  key_name      = "ssh_nathandevops"  # Nom de la cl SSH existante  vpc_security_group_ids = [aws_security_group.allow_all_tcp.id]  root_block_device {    volume_size = 20  # Taille du volume en Go    volume_type = "gp2"  # Type de volume SSD  usage gnral  }  # Script de dmarrage pour installer Docker sur Debian  user_data = <<-EOF              #!/bin/bash              apt update              apt install -y docker.io              systemctl start docker              usermod -aG docker admin              EOF  tags = {    Name = "DockerInstance-${count.index + 1}"  }}resource "local_file" "inventory" {  filename = "inventory.ini"  content  = <<-EOF    [managers]    ${aws_instance.web[0].public_ip}    [workers]    ${join("\n", slice(aws_instance.web[*].public_ip, 1, 3))}    EOF  depends_on = [aws_instance.web]}output "instance_ips" {  value = aws_instance.web[*].public_ip}
```

### /Users/lucas/Developer/cloud-webapp-auto-deploy/main-ssh.tf
```
# Declare variablesvariable "google_project_id" {  description = "Google Cloud project ID"  type        = string}variable "google_credentials" {  description = "Path to the Google Cloud credentials JSON file"  type        = string}variable "ssh_user" {  description = "SSH user name"  type        = string}# Configure the Google Cloud providerprovider "google" {  credentials = file(var.google_credentials)  project     = var.google_project_id  region      = "us-central1"}# Generate a new SSH key pairresource "tls_private_key" "ssh_key" {  algorithm = "RSA"  rsa_bits  = 4096}# Manage project metadataresource "google_compute_project_metadata" "my_project_metadata" {  metadata = {    ssh-keys = "${var.ssh_user}:${trimspace(tls_private_key.ssh_key.public_key_openssh)}"  }}# Define the VM instancesresource "google_compute_instance" "tp_sdv_cloud" {  count        = 3  name         = "tpsdvcloud${count.index + 1}"  machine_type = "e2-medium"  zone         = "us-central1-f"  boot_disk {    auto_delete = true    initialize_params {      image = "debian-cloud/debian-12-bookworm"      size  = 10      type  = "pd-standard"    }  }  network_interface {    network = "default"    access_config {      // Ephemeral IP    }  }  # Allow SSH access  tags = ["allow-ssh"]  metadata_startup_script = <<-EOF    #!/bin/bash    echo "Installing Docker..."    apt-get update    apt-get install -y docker.io    systemctl enable docker    systemctl start docker    echo "Docker installation completed"  EOF  service_account {    email  = "915723698108-compute@developer.gserviceaccount.com"    scopes = [      "https://www.googleapis.com/auth/devstorage.read_only",      "https://www.googleapis.com/auth/logging.write",      "https://www.googleapis.com/auth/monitoring.write",      "https://www.googleapis.com/auth/service.management.readonly",      "https://www.googleapis.com/auth/servicecontrol",      "https://www.googleapis.com/auth/trace.append"    ]  }}# Firewall rule to allow SSH accessresource "google_compute_firewall" "allow_ssh" {  name    = "allow-ssh"  network = "default"  allow {    protocol = "tcp"    ports    = ["22"]  }  source_ranges = ["0.0.0.0/0"]  target_tags   = ["allow-ssh"]  lifecycle {    create_before_destroy = true  }}# Output the private key for CI/CD useoutput "private_key" {  value     = tls_private_key.ssh_key.private_key_pem  sensitive = true}# Output to display the external IP addresses of the VMsoutput "vm_external_ips" {  value = google_compute_instance.tp_sdv_cloud[*].network_interface[0].access_config[0].nat_ip}
```

### /Users/lucas/Developer/cloud-webapp-auto-deploy/main.tf
```
# Configure the Google Cloud providerprovider "google" {  credentials = file("credentials.json")  project     = "student-sup-de-vinci"  region      = "us-central1"  zone        = "us-central1-f"}# Define the VM instancesresource "google_compute_instance" "tp_sdv_cloud" {  count        = 3  name         = "tpsdvcloud${count.index + 1}"  machine_type = "t2a-standard-1"  zone         = "us-central1-f"  boot_disk {    auto_delete = true    device_name = "tpsdvcloud${count.index + 1}"    initialize_params {      image = "projects/debian-cloud/global/images/debian-12-bookworm-arm64-v20240910"      size  = 10      type  = "pd-standard"    }    mode = "READ_WRITE"  }  can_ip_forward      = false  deletion_protection = false  enable_display      = false  labels = {    goog-ec-src = "vm_add-tf"  }  network_interface {    access_config {      network_tier = "PREMIUM"    }    nic_type    = "GVNIC"    queue_count = 0    stack_type  = "IPV4_ONLY"    subnetwork  = "projects/student-sup-de-vinci/regions/us-central1/subnetworks/default"  }  scheduling {    automatic_restart   = true    on_host_maintenance = "TERMINATE"    preemptible         = false    provisioning_model  = "STANDARD"  }  service_account {    email  = "915723698108-compute@developer.gserviceaccount.com"    scopes = [      "https://www.googleapis.com/auth/devstorage.read_only",      "https://www.googleapis.com/auth/logging.write",      "https://www.googleapis.com/auth/monitoring.write",      "https://www.googleapis.com/auth/service.management.readonly",      "https://www.googleapis.com/auth/servicecontrol",      "https://www.googleapis.com/auth/trace.append"    ]  }  shielded_instance_config {    enable_integrity_monitoring = true    enable_secure_boot          = false    enable_vtpm                 = true  }  # Script to install Docker.io and configure VM  metadata_startup_script = <<-EOF    #!/bin/bash    echo "Installing Docker.io"    # Update the package database    apt-get update    # Install Docker.io    apt-get install -y docker.io    # Enable Docker service to start on boot    systemctl enable docker    # Start Docker service    systemctl start docker    # Add the user to the Docker group (if you want to run Docker as a non-root user)    #usermod -aG docker $USER    echo "Docker installation completed"  EOF}# Output to display the internal IP of the first VMoutput "first_vm_internal_ip" {  value = google_compute_instance.tp_sdv_cloud[0].network_interface[0].network_ip}
```

### /Users/lucas/Developer/cloud-webapp-auto-deploy/swarm_init.yml
```
---- name: Deploy Docker Swarm Stack  hosts: all  become: yes  vars:    ansible_user: admin    ansible_ssh_private_key_file: ssh.pem    ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'  tasks:    - name: Ensure Docker is installed      apt:        name:          - docker.io          - python3-docker        state: present        update_cache: yes    - name: Ensure Docker service is started and enabled      systemd:        name: docker        state: started        enabled: yes    - name: Initialize Docker Swarm on manager      docker_swarm:        state: present      when: inventory_hostname == groups['managers'][0]      register: swarm_info    - name: Get swarm manager join token      command: docker swarm join-token -q manager      when: inventory_hostname == groups['managers'][0]      register: manager_token    - name: Get swarm worker join token      command: docker swarm join-token -q worker      when: inventory_hostname == groups['managers'][0]      register: worker_token    - name: Join additional managers to swarm      docker_swarm:        state: join        advertise_addr: "{{ ansible_default_ipv4.address }}"        join_token: "{{ hostvars[groups['managers'][0]]['manager_token']['stdout'] }}"        remote_addrs: [ "{{ hostvars[groups['managers'][0]]['ansible_default_ipv4']['address'] }}" ]      when: inventory_hostname in groups['managers'][1:]    - name: Join workers to swarm      docker_swarm:        state: join        advertise_addr: "{{ ansible_default_ipv4.address }}"        join_token: "{{ hostvars[groups['managers'][0]]['worker_token']['stdout'] }}"        remote_addrs: [ "{{ hostvars[groups['managers'][0]]['ansible_default_ipv4']['address'] }}" ]      when: inventory_hostname in groups['workers']    - name: Create docker-compose.yml      copy:        dest: /root/docker-compose.yml        content: |          version: '3.8'          services:            fastapi:              image: ghcr.io/phromaj/cloud-webapp-auto-deploy:latest              deploy:                mode: global              environment:                - DATABASE_URL=postgresql://postgres:password@myapp_db:5432/mydatabase              depends_on:                - db              networks:                - myapp_network            db:              image: postgres:15-alpine              deploy:                replicas: 1                placement:                  constraints: [node.role == manager]              environment:                POSTGRES_USER: postgres                POSTGRES_PASSWORD: password                POSTGRES_DB: mydatabase              volumes:                - postgres_data:/var/lib/postgresql/data              networks:                - myapp_network            caddy:              image: caddy:latest              deploy:                replicas: 1                placement:                  constraints: [node.role == manager]              ports:                - target: 80                  published: 80                  protocol: tcp                  mode: host                - target: 443                  published: 443                  protocol: tcp                  mode: host              volumes:                - caddy_data:/data                - caddy_config:/config              configs:                - source: caddy_config                  target: /etc/caddy/Caddyfile              depends_on:                - fastapi              networks:                - myapp_network          networks:            myapp_network:              driver: overlay          volumes:            postgres_data:            caddy_data:            caddy_config:          configs:            caddy_config:              file: ./Caddyfile      when: inventory_hostname == groups['managers'][0]    - name: Create Caddyfile      copy:        dest: /root/Caddyfile        content: |          :80 {              reverse_proxy fastapi:8000          }      when: inventory_hostname == groups['managers'][0]    - name: Deploy stack      command: docker stack deploy -c /root/docker-compose.yml myapp      when: inventory_hostname == groups['managers'][0]    - name: Wait for services to stabilize      command: docker stack services myapp      register: service_status      until: "'0/3' not in service_status.stdout"      retries: 30      delay: 10      when: inventory_hostname == groups['managers'][0]    - name: Display service status      debug:        var: service_status.stdout_lines      when: inventory_hostname == groups['managers'][0]    - name: Check service logs      command: docker service logs {{ item }} --tail 50      loop:        - myapp_fastapi        - myapp_db        - myapp_caddy      register: service_logs      when: inventory_hostname == groups['managers'][0]    - name: Display service logs      debug:        var: item.stdout_lines      loop: "{{ service_logs.results }}"      when: inventory_hostname == groups['managers'][0]
```

